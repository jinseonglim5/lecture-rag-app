import os
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from tempfile import NamedTemporaryFile
from langchain.schema import HumanMessage
from langchain.text_splitter import RecursiveCharacterTextSplitter
from PyPDF2 import PdfReader
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
# ì„ë² ë”© ëª¨ë¸
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_text_from_pdf(file):
    reader = PdfReader(file)
    text_per_page = []
    for i, page in enumerate(reader.pages):
        text = page.extract_text()
        if text:
            text_per_page.append({"page": i+1, "text": text})
    return text_per_page

# ìš”ì•½ í•¨ìˆ˜ (ì²­í¬ ê¸°ë°˜)
def summarize_chunks(chunks):
    summaries = []
    for idx, chunk in enumerate(chunks):
        prompt = f"ë‹¤ìŒì€ ê°•ì˜ìë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  í•µì‹¬ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš” (Part {idx+1}):\n\n{chunk}"
        res = llm([HumanMessage(content=prompt)])
        summaries.append(res.content)
    return "\n\n".join(summaries)

# ì—°ìŠµë¬¸ì œ ìƒì„± í•¨ìˆ˜
def generate_quiz(summary, num_questions=20):
    prompt = f"ë‹¤ìŒ ê°•ì˜ìë£Œ ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì‹, ì£¼ê´€ì‹, O/X, ë‹¨ë‹µí˜• ë¬¸ì œë¥¼ ê³¨ê³ ë£¨ ì„ì–´ ì´ {num_questions}ê°œì˜ ì—°ìŠµë¬¸ì œë¥¼ ìƒì„±í•´ì¤˜.\n\nìš”ì•½:\n{summary}"
    res = llm([HumanMessage(content=prompt)])
    return res.content

# Chromaì— ì €ì¥
def save_to_chroma(split_docs):
    vectordb = Chroma.from_documents(split_docs, embedding=embedding_model, persist_directory="chroma_db")
    vectordb.persist()

# ê²€ìƒ‰
def search_chroma(query):
    vectordb = Chroma(persist_directory="chroma_db", embedding_function=embedding_model)
    retriever = vectordb.as_retriever()
    docs = retriever.get_relevant_documents(query)
    return docs

# LLM ì„¤ì •
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    google_api_key=GEMINI_API_KEY,
    temperature=0.7,
)

st.title("ğŸ“š ê°•ì˜ìë£Œ ìš”ì•½ ë° ì—°ìŠµë¬¸ì œ ìƒì„±ê¸° (ë©€í‹° PDF ì§€ì›)")

uploaded_files = st.file_uploader("ğŸ“¤ ì—¬ëŸ¬ PDF ì—…ë¡œë“œ", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_docs = []
    for uploaded_file in uploaded_files:
        st.info(f"âœ… {uploaded_file.name} ì—…ë¡œë“œ ì™„ë£Œ")
        text_per_page = extract_text_from_pdf(uploaded_file)
        for item in text_per_page:
            all_docs.append({"text": item["text"], "source": uploaded_file.name, "page": item["page"]})

    # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    full_text = "\n\n".join([doc["text"] for doc in all_docs])

    # í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
    splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=200)
    split_docs = splitter.create_documents([doc["text"] for doc in all_docs])

    with st.spinner("ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤..."):
        summary = summarize_chunks([doc.page_content for doc in split_docs])
        st.subheader("ğŸ“ ìš”ì•½ ê²°ê³¼")
        st.write(summary)

    with st.spinner("ì—°ìŠµë¬¸ì œ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        quiz = generate_quiz(summary, num_questions=20)
        st.subheader("â“ ì—°ìŠµë¬¸ì œ")
        st.write(quiz)

    with st.spinner("ChromaDB ì €ì¥ ì¤‘ì…ë‹ˆë‹¤..."):
        save_to_chroma(split_docs)
        st.success("âœ… ChromaDB ì €ì¥ ì™„ë£Œ")

    query = st.text_input("ğŸ¤– ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ê°•ì˜ìë£Œ ê´€ë ¨)")

    if query:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            vectordb = Chroma(persist_directory="chroma_db", embedding_function=embedding_model)
            retriever = vectordb.as_retriever()
            qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type="stuff")
            response = qa_chain.run(query)
            st.subheader("ğŸ’¬ Geminiì˜ ë‹µë³€")
            st.write(response)

    keyword = st.text_input("ğŸ” íŠ¹ì • í‚¤ì›Œë“œê°€ ì–´ë–¤ ë¬¸ì„œ ëª‡ í˜ì´ì§€ì— ìˆëŠ”ì§€ ì°¾ê¸°")
    if keyword:
        with st.spinner("ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            results = search_chroma(keyword)
            st.subheader("ğŸ” ê²€ìƒ‰ ê²°ê³¼")
            for i, doc in enumerate(results):
                st.write(f"{i+1}. ì¼ë¶€ ë‚´ìš©: {doc.page_content[:300]}...")
